{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import yfinance as yf\n",
    "from os import path\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Symbol  1993-01-29 00:00:00  1993-02-01 00:00:00  1993-02-02 00:00:00  \\\n",
      "0      ABEQ                  NaN                  NaN                  NaN   \n",
      "1      ACES                  NaN                  NaN                  NaN   \n",
      "2      ACIO                  NaN                  NaN                  NaN   \n",
      "3      ACSI                  NaN                  NaN                  NaN   \n",
      "4       ACT                  NaN                  NaN                  NaN   \n",
      "...     ...                  ...                  ...                  ...   \n",
      "1544    YYY                  NaN                  NaN                  NaN   \n",
      "1545   ZCAN                  NaN                  NaN                  NaN   \n",
      "1546    ZIG                  NaN                  NaN                  NaN   \n",
      "1547   ZMLP                  NaN                  NaN                  NaN   \n",
      "1548   ZROZ                  NaN                  NaN                  NaN   \n",
      "\n",
      "      1993-02-03 00:00:00  1993-02-04 00:00:00  1993-02-05 00:00:00  \\\n",
      "0                     NaN                  NaN                  NaN   \n",
      "1                     NaN                  NaN                  NaN   \n",
      "2                     NaN                  NaN                  NaN   \n",
      "3                     NaN                  NaN                  NaN   \n",
      "4                     NaN                  NaN                  NaN   \n",
      "...                   ...                  ...                  ...   \n",
      "1544                  NaN                  NaN                  NaN   \n",
      "1545                  NaN                  NaN                  NaN   \n",
      "1546                  NaN                  NaN                  NaN   \n",
      "1547                  NaN                  NaN                  NaN   \n",
      "1548                  NaN                  NaN                  NaN   \n",
      "\n",
      "      1993-02-08 00:00:00  1993-02-09 00:00:00  1993-02-10 00:00:00  ...  \\\n",
      "0                     NaN                  NaN                  NaN  ...   \n",
      "1                     NaN                  NaN                  NaN  ...   \n",
      "2                     NaN                  NaN                  NaN  ...   \n",
      "3                     NaN                  NaN                  NaN  ...   \n",
      "4                     NaN                  NaN                  NaN  ...   \n",
      "...                   ...                  ...                  ...  ...   \n",
      "1544                  NaN                  NaN                  NaN  ...   \n",
      "1545                  NaN                  NaN                  NaN  ...   \n",
      "1546                  NaN                  NaN                  NaN  ...   \n",
      "1547                  NaN                  NaN                  NaN  ...   \n",
      "1548                  NaN                  NaN                  NaN  ...   \n",
      "\n",
      "      2020-10-05 00:00:00  2020-10-06 00:00:00  2020-10-07 00:00:00  \\\n",
      "0               23.570000            23.570000            23.469999   \n",
      "1               57.189999            58.709999            59.639999   \n",
      "2               26.559999            26.830000            26.590000   \n",
      "3               38.210999            37.730999            38.507999   \n",
      "4               26.430000            26.813999            26.900000   \n",
      "...                   ...                  ...                  ...   \n",
      "1544            14.690000            14.830000            14.850000   \n",
      "1545            57.880001            58.340000            58.080002   \n",
      "1546            22.285000            22.290001            22.309999   \n",
      "1547            49.860001            51.060001            51.330002   \n",
      "1548           167.580002           165.000000           165.339996   \n",
      "\n",
      "      2020-10-08 00:00:00  2020-10-09 00:00:00  2020-10-12 00:00:00  \\\n",
      "0               23.760000            23.780001            24.025000   \n",
      "1               62.099998            60.700001            62.490002   \n",
      "2               26.930000            26.980000            27.360001   \n",
      "3               38.648998            39.060001            39.330002   \n",
      "4               26.889999            27.420000            27.650000   \n",
      "...                   ...                  ...                  ...   \n",
      "1544            14.900000            15.000000            14.970000   \n",
      "1545            58.779999            59.290001            59.669998   \n",
      "1546            22.410000            22.664000            22.760000   \n",
      "1547            50.900002            53.730000            53.500000   \n",
      "1548           165.699997           165.130005           166.089996   \n",
      "\n",
      "      2020-10-13 00:00:00  2020-10-14 00:00:00  2020-10-15 00:00:00  \\\n",
      "0               23.870001            23.882000            23.700001   \n",
      "1               60.400002            61.029999            59.650002   \n",
      "2               27.549999            27.299999            26.870001   \n",
      "3               39.652000            39.330002            39.457001   \n",
      "4               27.350000            27.450001            27.170000   \n",
      "...                   ...                  ...                  ...   \n",
      "1544            15.000000            14.950000            14.890000   \n",
      "1545            59.139999            59.160000            58.250000   \n",
      "1546            23.049999            23.160000            22.799999   \n",
      "1547            53.669998            53.509998            53.180000   \n",
      "1548           167.429993           169.279999           170.429993   \n",
      "\n",
      "      2020-10-16 00:00:00  \n",
      "0               23.889999  \n",
      "1               60.980000  \n",
      "2               27.200001  \n",
      "3               39.471001  \n",
      "4               27.590000  \n",
      "...                   ...  \n",
      "1544            14.890000  \n",
      "1545            58.990002  \n",
      "1546            23.059999  \n",
      "1547            53.799999  \n",
      "1548           168.110001  \n",
      "\n",
      "[1549 rows x 6983 columns]\n"
     ]
    }
   ],
   "source": [
    "# get list of symbols\n",
    "etf_histories_path = './etf_histories.csv'\n",
    "df_histories = None\n",
    "if path.exists(etf_histories_path):\n",
    "    df_histories = pd.read_csv(etf_histories_path)\n",
    "else:\n",
    "    etf_details = pd.read_csv('./etfs_details_type_fund_flow.csv')\n",
    "    symbols = etf_details['Symbol'].tolist()\n",
    "\n",
    "\n",
    "    histories = yf.download(symbols, period='max', interval='1d')\n",
    "\n",
    "    df_histories = histories\n",
    "\n",
    "    df_histories = (df_histories\n",
    "                    .drop(['Adj Close', 'Close', 'Volume', 'High', 'Low'], axis=1)\n",
    "                    .transpose()\n",
    "                    .reset_index()\n",
    "                    .drop(['level_0'], axis=1)\n",
    "                    .rename(columns={ 'level_1': 'Symbol' })\n",
    "                    .set_index('Symbol')\n",
    "                   )\n",
    "    df_histories.to_csv('./etf_histories.csv')\n",
    "    \n",
    "print(df_histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all symbols recorded to files\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get list of symbols\n",
    "etf_details = pd.read_csv('./etfs_details_type_fund_flow.csv')\n",
    "symbols = etf_details['Symbol'].tolist()\n",
    "\n",
    "# iterate over symbols to produce historical data\n",
    "i = 0\n",
    "for ticker in symbols:\n",
    "    etf_file_path = './etf/' + ticker + '.csv'\n",
    "    \n",
    "    if not path.exists(etf_file_path):\n",
    "        etf = yf.Ticker(ticker)\n",
    "        etf_df = etf.history(period='max')\n",
    "\n",
    "        etf_df.to_csv(etf_file_path)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    if i == len(symbols) - 1:\n",
    "        print('all symbols recorded to files')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date\n",
      "0  1980-01-01\n",
      "1  1980-02-01\n",
      "2  1980-03-01\n",
      "3  1980-04-01\n",
      "4  1980-05-01\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./etf/AGG.csv')\n",
    "\n",
    "dates = np.arange(np.datetime64('1980-01-01'), np.datetime64('today'), np.timedelta64(1, 'M'), dtype='datetime64[M]').astype('datetime64[D]').astype(str)\n",
    "\n",
    "\n",
    "df['AGG'] = df['Open']\n",
    "df = df.drop(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame(np.random.randn(len(dates), 4), columns=['A', 'B', 'C', 'D'], index=dates)\n",
    "df1['Date'] = df1.index\n",
    "df1 = df1.reset_index()\n",
    "df1 = df1.drop('index', axis=1)\n",
    "df_merged = df1\n",
    "df_merged = df_merged.drop(['A', 'B', 'C', 'D'], axis=1)\n",
    "print(df_merged.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_etf_name(filename):\n",
    "    return filename.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_column(df, col_name):\n",
    "    if col_name in df.columns.tolist():\n",
    "        df = df.drop(col_name, axis=1)\n",
    "    return df\n",
    "\n",
    "def get_cleaned_etf(dirname, filename):\n",
    "    etf_name = get_etf_name(filename)    \n",
    "    df = pd.read_csv(dirname + '/' + filename)\n",
    "        \n",
    "    df[etf_name] = df['Open']\n",
    "\n",
    "    drop_list = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Dividends', 'Stock Splits', 'Size']\n",
    "    for col in drop_list:\n",
    "        df = drop_column(df, col)\n",
    "        \n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "etfs_available = 0\n",
    "\n",
    "def get_cleaned_data():\n",
    "    global etfs_available\n",
    "    global df_merged\n",
    "    \n",
    "#     if path.exists('./cleaned-data.csv'):\n",
    "#         print('file exists')\n",
    "#     else:\n",
    "#         print('file does not exist')\n",
    "    \n",
    "    cleaned_data_path = './cleaned-data.csv'\n",
    "    \n",
    "    i = 0\n",
    "    for dirname, _, filenames in os.walk('./etf'):\n",
    "        etfs_available = len(filenames)\n",
    "        \n",
    "#         if path.exists(cleaned_data_path):\n",
    "#             return pd.read_csv(cleaned_data_path)\n",
    "        \n",
    "        for filename in filenames:\n",
    "            if filename[0] != '.':\n",
    "                df = get_cleaned_etf(dirname, filename)\n",
    "                if isinstance(df, pd.DataFrame):\n",
    "                    # work with it\n",
    "                    df_merged = df_merged.merge(df, on='Date', how='left')\n",
    "                    print('cleaned ' + filename)\n",
    "#                     df_merged.to_csv(cleaned_data_path)\n",
    "\n",
    "                i += 1\n",
    "\n",
    "                if (i == len(filenames)):\n",
    "                    print('finished parsing files')\n",
    "                    \n",
    "#     df_merged.to_csv(cleaned_data_path)\n",
    "                    \n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned SPXB.csv\n",
      "cleaned PSM.csv\n",
      "cleaned SPXU.csv\n",
      "cleaned PPA.csv\n",
      "cleaned USTB.csv\n",
      "cleaned XSHD.csv\n",
      "cleaned BBSA.csv\n",
      "cleaned BBRE.csv\n",
      "cleaned TRND.csv\n",
      "cleaned QDIV.csv\n",
      "cleaned RDVY.csv\n",
      "cleaned VONG.csv\n",
      "cleaned HYLB.csv\n",
      "cleaned JHMH.csv\n",
      "cleaned SUSA.csv\n",
      "cleaned IHE.csv\n",
      "cleaned SPLG.csv\n",
      "cleaned DXGE.csv\n",
      "cleaned CSD.csv\n",
      "cleaned BSEP.csv\n",
      "cleaned DVY.csv\n",
      "cleaned FMF.csv\n",
      "cleaned IBDV.csv\n",
      "cleaned EQRR.csv\n",
      "cleaned IBHB.csv\n",
      "cleaned DRSK.csv\n",
      "cleaned RWVG.csv\n",
      "cleaned FCPI.csv\n",
      "cleaned FVL.csv\n",
      "cleaned TIP.csv\n",
      "cleaned LACK.csv\n",
      "cleaned SMLV.csv\n",
      "cleaned ARB.csv\n",
      "cleaned TOTL.csv\n",
      "cleaned DBMF.csv\n",
      "cleaned RBUS.csv\n",
      "cleaned FYT.csv\n",
      "cleaned STLC.csv\n",
      "cleaned XSD.csv\n",
      "cleaned FYC.csv\n",
      "cleaned XPH.csv\n",
      "cleaned DGRW.csv\n",
      "cleaned FXG.csv\n",
      "cleaned IUSS.csv\n",
      "cleaned SCC.csv\n",
      "cleaned VIXM.csv\n",
      "cleaned TFI.csv\n",
      "cleaned CGW.csv\n",
      "cleaned MID.csv\n",
      "cleaned CDL.csv\n",
      "cleaned TDV.csv\n",
      "cleaned SZNE.csv\n",
      "cleaned SMMD.csv\n",
      "cleaned XITK.csv\n",
      "cleaned KOMP.csv\n",
      "cleaned SMH.csv\n",
      "cleaned DXD.csv\n",
      "cleaned TDSB.csv\n",
      "cleaned VDC.csv\n",
      "cleaned FAD.csv\n",
      "cleaned PSMM.csv\n",
      "cleaned IBHC.csv\n",
      "cleaned SFIG.csv\n",
      "cleaned FAS.csv\n",
      "cleaned QAI.csv\n",
      "cleaned RISN.csv\n",
      "cleaned ESGG.csv\n",
      "cleaned PSCF.csv\n",
      "cleaned VIS.csv\n",
      "cleaned CPI.csv\n",
      "cleaned QMJ.csv\n",
      "cleaned FNK.csv\n",
      "cleaned BIZD.csv\n",
      "cleaned USMV.csv\n",
      "cleaned IDIV.csv\n",
      "cleaned KRMA.csv\n",
      "cleaned SPMB.csv\n",
      "cleaned PFM.csv\n",
      "cleaned PREF.csv\n",
      "cleaned JHMI.csv\n",
      "cleaned GMOM.csv\n",
      "cleaned GOVZ.csv\n",
      "cleaned ENFR.csv\n",
      "cleaned SPUS.csv\n",
      "cleaned SIXA.csv\n",
      "cleaned VCLT.csv\n",
      "cleaned ARKW.csv\n",
      "cleaned SPXT.csv\n",
      "cleaned HYTR.csv\n",
      "cleaned IMTB.csv\n",
      "cleaned PSL.csv\n",
      "cleaned RHS.csv\n",
      "cleaned SPYG.csv\n",
      "cleaned XMMO.csv\n",
      "cleaned MMIN.csv\n",
      "cleaned DTEC.csv\n",
      "cleaned VSDA.csv\n",
      "cleaned SPXV.csv\n",
      "cleaned MTGP.csv\n",
      "cleaned HIPS.csv\n",
      "cleaned RGI.csv\n",
      "cleaned UBT.csv\n",
      "cleaned EPOL.csv\n",
      "cleaned LGLV.csv\n",
      "cleaned BAB.csv\n",
      "cleaned QABA.csv\n",
      "cleaned BUG.csv\n",
      "cleaned HYLV.csv\n",
      "cleaned IEV.csv\n",
      "cleaned LEAD.csv\n",
      "cleaned ALTS.csv\n",
      "cleaned AGGY.csv\n",
      "cleaned SPBO.csv\n",
      "cleaned USMC.csv\n",
      "cleaned PDP.csv\n",
      "cleaned VALT.csv\n",
      "cleaned SUSB.csv\n",
      "cleaned IHF.csv\n",
      "cleaned YGRN.csv\n",
      "cleaned LTL.csv\n",
      "cleaned IQSU.csv\n",
      "cleaned DSTL.csv\n",
      "cleaned FLV.csv\n",
      "cleaned PTEU.csv\n",
      "cleaned IBDU.csv\n",
      "cleaned KDFI.csv\n",
      "cleaned PSCD.csv\n",
      "cleaned JXI.csv\n",
      "cleaned IBHA.csv\n",
      "cleaned BSJK.csv\n",
      "cleaned PJAN.csv\n",
      "cleaned XJR.csv\n",
      "cleaned ULVM.csv\n",
      "cleaned ULTR.csv\n",
      "cleaned SLY.csv\n",
      "cleaned HTEC.csv\n",
      "cleaned EFIV.csv\n",
      "cleaned OMFS.csv\n",
      "cleaned FXD.csv\n",
      "cleaned DBLV.csv\n",
      "cleaned MJJ.csv\n",
      "cleaned XRT.csv\n",
      "cleaned PFLD.csv\n",
      "cleaned STLV.csv\n",
      "cleaned MUNI.csv\n",
      "cleaned DRIP.csv\n",
      "cleaned VIXY.csv\n",
      "cleaned FFTG.csv\n",
      "cleaned TQQQ.csv\n",
      "cleaned FXR.csv\n",
      "cleaned LDRS.csv\n",
      "cleaned SOXS.csv\n",
      "cleaned IUSG.csv\n",
      "cleaned BOCT.csv\n",
      "cleaned BOND.csv\n",
      "cleaned RYLD.csv\n",
      "cleaned DON.csv\n",
      "cleaned TDSA.csv\n",
      "cleaned VFH.csv\n",
      "cleaned PSCE.csv\n",
      "cleaned CSF.csv\n",
      "cleaned VIG.csv\n",
      "cleaned IBDT.csv\n",
      "cleaned EMLP.csv\n",
      "cleaned DTD.csv\n",
      "cleaned OEF.csv\n",
      "cleaned VHT.csv\n",
      "cleaned VIOG.csv\n",
      "cleaned ESGS.csv\n",
      "cleaned VTWG.csv\n",
      "cleaned SPMV.csv\n",
      "cleaned DFNL.csv\n",
      "cleaned SUSC.csv\n",
      "cleaned FUTY.csv\n",
      "cleaned YLD.csv\n",
      "cleaned VOOV.csv\n",
      "cleaned VONE.csv\n",
      "cleaned SPAB.csv\n",
      "cleaned IMLP.csv\n",
      "cleaned RPV.csv\n",
      "cleaned VFQY.csv\n",
      "cleaned XSHQ.csv\n",
      "cleaned NOCT.csv\n",
      "cleaned VMBS.csv\n",
      "cleaned CAPE.csv\n",
      "cleaned REW.csv\n",
      "cleaned PBTP.csv\n",
      "cleaned HYXE.csv\n",
      "cleaned HIPR.csv\n",
      "cleaned RAFE.csv\n",
      "cleaned VMOT.csv\n",
      "cleaned SPYD.csv\n",
      "cleaned TECL.csv\n",
      "cleaned SPXS.csv\n",
      "cleaned AIRR.csv\n",
      "cleaned PSK.csv\n",
      "cleaned EWGS.csv\n",
      "cleaned MORT.csv\n",
      "cleaned IVOO.csv\n",
      "cleaned BNDC.csv\n",
      "cleaned XCOM.csv\n",
      "cleaned QQQN.csv\n",
      "cleaned ARKG.csv\n",
      "cleaned HLAL.csv\n",
      "cleaned GOAT.csv\n",
      "cleaned FLCA.csv\n",
      "cleaned KIE.csv\n",
      "cleaned PRFZ.csv\n",
      "cleaned LKOR.csv\n",
      "cleaned HYLS.csv\n",
      "cleaned VONV.csv\n",
      "cleaned DMRM.csv\n",
      "cleaned HYLD.csv\n",
      "cleaned EQL.csv\n",
      "cleaned EWRE.csv\n",
      "cleaned IJK.csv\n",
      "cleaned GDX.csv\n",
      "cleaned UAPR.csv\n",
      "cleaned SPLV.csv\n",
      "cleaned USMF.csv\n",
      "cleaned USLB.csv\n",
      "cleaned VALQ.csv\n",
      "cleaned IBDP.csv\n",
      "cleaned CSB.csv\n",
      "cleaned LMBS.csv\n",
      "cleaned HCRB.csv\n",
      "cleaned BSJN.csv\n",
      "cleaned IBHD.csv\n",
      "cleaned VETS.csv\n",
      "cleaned JEPI.csv\n",
      "cleaned VB.csv\n",
      "cleaned PJUN.csv\n",
      "cleaned TAXF.csv\n",
      "cleaned FTEC.csv\n",
      "cleaned MJO.csv\n",
      "cleaned GURU.csv\n",
      "cleaned IUSB.csv\n",
      "cleaned JULZ.csv\n",
      "cleaned SMMU.csv\n",
      "cleaned SMN.csv\n",
      "cleaned VSL.csv\n",
      "cleaned VRAI.csv\n",
      "cleaned CIZ.csv\n",
      "cleaned FTC.csv\n",
      "cleaned SMLF.csv\n",
      "cleaned MRGR.csv\n",
      "cleaned IBHE.csv\n",
      "cleaned PASS.csv\n",
      "cleaned VDE.csv\n",
      "cleaned BSJO.csv\n",
      "cleaned FAB.csv\n",
      "cleaned ESHY.csv\n",
      "cleaned ESGV.csv\n",
      "cleaned NEAR.csv\n",
      "cleaned TOLZ.csv\n",
      "cleaned IECS.csv\n",
      "cleaned ESGA.csv\n",
      "cleaned IBDQ.csv\n",
      "cleaned UXI.csv\n",
      "cleaned SPMD.csv\n",
      "cleaned BLES.csv\n",
      "cleaned TPOR.csv\n",
      "cleaned UYM.csv\n",
      "cleaned MXDU.csv\n",
      "cleaned JHCS.csv\n",
      "cleaned IJJ.csv\n",
      "cleaned PGX.csv\n",
      "cleaned SGOV.csv\n",
      "cleaned DMRL.csv\n",
      "cleaned IGM.csv\n",
      "cleaned TPAY.csv\n",
      "cleaned EEH.csv\n",
      "cleaned ARKQ.csv\n",
      "cleaned ERUS.csv\n",
      "cleaned EUSB.csv\n",
      "cleaned UCC.csv\n",
      "cleaned SPUU.csv\n",
      "cleaned GOAU.csv\n",
      "cleaned ICVT.csv\n",
      "cleaned USVM.csv\n",
      "cleaned USXF.csv\n",
      "cleaned PRN.csv\n",
      "cleaned FLOT.csv\n",
      "cleaned BLV.csv\n",
      "cleaned MCEF.csv\n",
      "cleaned SPXE.csv\n",
      "cleaned PSJ.csv\n",
      "cleaned HYUP.csv\n",
      "cleaned SPYV.csv\n",
      "cleaned BNKZ.csv\n",
      "cleaned CORP.csv\n",
      "cleaned SPYC.csv\n",
      "cleaned FLMI.csv\n",
      "cleaned QMOM.csv\n",
      "cleaned BNKO.csv\n",
      "cleaned QCLN.csv\n",
      "cleaned FLCB.csv\n",
      "cleaned GSSC.csv\n",
      "cleaned SPTS.csv\n",
      "cleaned HYXU.csv\n",
      "cleaned IVOL.csv\n",
      "cleaned PBUS.csv\n",
      "cleaned GSST.csv\n",
      "cleaned BBH.csv\n",
      "cleaned JAGG.csv\n",
      "cleaned JHMM.csv\n",
      "cleaned ESG.csv\n",
      "cleaned PHB.csv\n",
      "cleaned SIMS.csv\n",
      "cleaned UDOW.csv\n",
      "cleaned IJH.csv\n",
      "cleaned PFI.csv\n",
      "cleaned SPLB.csv\n",
      "cleaned FIDU.csv\n",
      "cleaned FNX.csv\n",
      "cleaned DUG.csv\n",
      "cleaned CSA.csv\n",
      "cleaned BTAL.csv\n",
      "cleaned IBDS.csv\n",
      "cleaned TAAG.csv\n",
      "cleaned FQAL.csv\n",
      "cleaned XWEB.csv\n",
      "cleaned PSCU.csv\n",
      "cleaned QMN.csv\n",
      "cleaned GBDV.csv\n",
      "cleaned IBDD.csv\n",
      "cleaned BSJM.csv\n",
      "cleaned PHYL.csv\n",
      "cleaned FTSM.csv\n",
      "cleaned VGK.csv\n",
      "cleaned VGLT.csv\n",
      "cleaned SSPY.csv\n",
      "cleaned ACSI.csv\n",
      "cleaned FTA.csv\n",
      "cleaned MGK.csv\n",
      "cleaned VPU.csv\n",
      "cleaned ACES.csv\n",
      "cleaned VV.csv\n",
      "cleaned RESP.csv\n",
      "cleaned STMB.csv\n",
      "cleaned NUSI.csv\n",
      "cleaned FXU.csv\n",
      "cleaned TAWK.csv\n",
      "cleaned STLG.csv\n",
      "cleaned FXC.csv\n",
      "cleaned DGRS.csv\n",
      "cleaned IUSV.csv\n",
      "cleaned CFA.csv\n",
      "cleaned XSW.csv\n",
      "cleaned LDSF.csv\n",
      "cleaned SBB.csv\n",
      "cleaned SMMV.csv\n",
      "cleaned VPC.csv\n",
      "cleaned DUAL.csv\n",
      "cleaned PJUL.csv\n",
      "cleaned ECLN.csv\n",
      "cleaned FTSL.csv\n",
      "cleaned BSJL.csv\n",
      "cleaned AGG.csv\n",
      "cleaned ESGU.csv\n",
      "cleaned MJ.csv\n",
      "cleaned PSCT.csv\n",
      "cleaned IBDR.csv\n",
      "cleaned FMB.csv\n",
      "cleaned PSCC.csv\n",
      "cleaned FNY.csv\n",
      "cleaned PFXF.csv\n",
      "cleaned VIOV.csv\n",
      "cleaned VTWV.csv\n",
      "cleaned FLZA.csv\n",
      "cleaned EWSC.csv\n",
      "cleaned IEF.csv\n",
      "cleaned VOOG.csv\n",
      "cleaned BKLN.csv\n",
      "cleaned HYMB.csv\n",
      "cleaned JHML.csv\n",
      "cleaned RPG.csv\n",
      "cleaned IGN.csv\n",
      "cleaned IDU.csv\n",
      "cleaned SIXS.csv\n",
      "cleaned JSML.csv\n",
      "cleaned DFVL.csv\n",
      "cleaned SPVM.csv\n",
      "cleaned EUSA.csv\n",
      "cleaned PSI.csv\n",
      "cleaned RFCI.csv\n",
      "cleaned QDEF.csv\n",
      "cleaned SECT.csv\n",
      "cleaned AGZD.csv\n",
      "cleaned ALFA.csv\n",
      "cleaned PXI.csv\n",
      "cleaned IWD.csv\n",
      "cleaned RVNU.csv\n",
      "cleaned IVW.csv\n",
      "cleaned NTSX.csv\n",
      "cleaned PYZ.csv\n",
      "cleaned PZA.csv\n",
      "cleaned IWS.csv\n",
      "cleaned JVAL.csv\n",
      "cleaned RTH.csv\n",
      "cleaned EWI.csv\n",
      "cleaned IAI.csv\n",
      "cleaned KXI.csv\n",
      "cleaned PRNT.csv\n",
      "cleaned EWUS.csv\n",
      "cleaned VFMV.csv\n",
      "cleaned PBP.csv\n",
      "cleaned WBIE.csv\n",
      "cleaned RAVI.csv\n",
      "cleaned DALT.csv\n",
      "cleaned FNDB.csv\n",
      "cleaned EPRF.csv\n",
      "cleaned KORP.csv\n",
      "cleaned AOK.csv\n",
      "cleaned BSCS.csv\n",
      "cleaned QLTA.csv\n",
      "cleaned FTXL.csv\n",
      "cleaned FVAL.csv\n",
      "cleaned XYLD.csv\n",
      "cleaned BJAN.csv\n",
      "cleaned XLE.csv\n",
      "cleaned JETS.csv\n",
      "cleaned VCR.csv\n",
      "cleaned STSB.csv\n",
      "cleaned EDOC.csv\n",
      "cleaned IBMM.csv\n",
      "cleaned SSUS.csv\n",
      "cleaned BSMO.csv\n",
      "cleaned IGEB.csv\n",
      "cleaned QQQ.csv\n",
      "cleaned RINF.csv\n",
      "cleaned TLH.csv\n",
      "cleaned GNOM.csv\n",
      "cleaned QSY.csv\n",
      "cleaned FPX.csv\n",
      "cleaned SDOG.csv\n",
      "cleaned TBT.csv\n",
      "cleaned GNAF.csv\n",
      "cleaned SHYG.csv\n",
      "cleaned WANT.csv\n",
      "cleaned JKH.csv\n",
      "cleaned SCHR.csv\n",
      "cleaned SMEZ.csv\n",
      "cleaned VXX.csv\n",
      "cleaned JKI.csv\n",
      "cleaned POCT.csv\n",
      "cleaned VRIG.csv\n",
      "cleaned TMDV.csv\n",
      "cleaned PALC.csv\n",
      "cleaned SDD.csv\n",
      "cleaned IIGD.csv\n",
      "cleaned GERM.csv\n",
      "cleaned SCHD.csv\n",
      "cleaned AVUV.csv\n",
      "cleaned SDS.csv\n",
      "cleaned VEGA.csv\n",
      "cleaned TNA.csv\n",
      "cleaned RING.csv\n",
      "cleaned ADFI.csv\n",
      "cleaned MUST.csv\n",
      "cleaned IBML.csv\n",
      "cleaned BSMN.csv\n",
      "cleaned FEX.csv\n",
      "cleaned FDRR.csv\n",
      "cleaned QDF.csv\n",
      "cleaned DEUS.csv\n",
      "cleaned DIAL.csv\n",
      "cleaned NRGZ.csv\n",
      "cleaned BSCR.csv\n",
      "cleaned BSCE.csv\n",
      "cleaned BTEC.csv\n",
      "cleaned AMU.csv\n",
      "cleaned PPTY.csv\n",
      "cleaned TPHD.csv\n",
      "cleaned FNGO.csv\n",
      "cleaned TEQI.csv\n",
      "cleaned USHY.csv\n",
      "cleaned FIBR.csv\n",
      "cleaned GHYG.csv\n",
      "cleaned WFH.csv\n",
      "cleaned QDYN.csv\n",
      "cleaned USFR.csv\n",
      "cleaned SPDN.csv\n",
      "cleaned SPFF.csv\n",
      "cleaned IBD.csv\n",
      "cleaned RWR.csv\n",
      "cleaned IWR.csv\n",
      "cleaned FLEE.csv\n",
      "cleaned EWMC.csv\n",
      "cleaned KBWP.csv\n",
      "cleaned IVV.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned VTHR.csv\n",
      "cleaned GSUS.csv\n",
      "cleaned CCOR.csv\n",
      "cleaned IXJ.csv\n",
      "cleaned RFFC.csv\n",
      "cleaned VTEB.csv\n",
      "cleaned TEGS.csv\n",
      "cleaned IYY.csv\n",
      "cleaned FRAK.csv\n",
      "cleaned ROMO.csv\n",
      "cleaned PXJ.csv\n",
      "cleaned RALS.csv\n",
      "cleaned KNG.csv\n",
      "cleaned IWP.csv\n",
      "cleaned KBWR.csv\n",
      "cleaned ICSH.csv\n",
      "cleaned SLVO.csv\n",
      "cleaned USI.csv\n",
      "cleaned FILL.csv\n",
      "cleaned PBS.csv\n",
      "cleaned WBIF.csv\n",
      "cleaned EZM.csv\n",
      "cleaned VFLQ.csv\n",
      "cleaned FNDA.csv\n",
      "cleaned FNGZ.csv\n",
      "cleaned NRGO.csv\n",
      "cleaned MLPO.csv\n",
      "cleaned IBCE.csv\n",
      "cleaned SSO.csv\n",
      "cleaned PSEP.csv\n",
      "cleaned XYLG.csv\n",
      "cleaned VOE.csv\n",
      "cleaned FTXO.csv\n",
      "cleaned MLPX.csv\n",
      "cleaned UITB.csv\n",
      "cleaned BSCP.csv\n",
      "cleaned STPZ.csv\n",
      "cleaned ETHO.csv\n",
      "cleaned QWLD.csv\n",
      "cleaned PTNQ.csv\n",
      "cleaned GBLO.csv\n",
      "cleaned XLF.csv\n",
      "cleaned EDOW.csv\n",
      "cleaned TFLT.csv\n",
      "cleaned FEZ.csv\n",
      "cleaned BSML.csv\n",
      "cleaned IEHS.csv\n",
      "cleaned IBMN.csv\n",
      "cleaned AFIF.csv\n",
      "cleaned SH.csv\n",
      "cleaned MBB.csv\n",
      "cleaned KOIN.csv\n",
      "cleaned QRFT.csv\n",
      "cleaned AMOM.csv\n",
      "cleaned SHE.csv\n",
      "cleaned PFFD.csv\n",
      "cleaned DBGR.csv\n",
      "cleaned MNA.csv\n",
      "cleaned ATMP.csv\n",
      "cleaned IGIB.csv\n",
      "cleaned SFY.csv\n",
      "cleaned JKK.csv\n",
      "cleaned SCHQ.csv\n",
      "cleaned SHYD.csv\n",
      "cleaned VXZ.csv\n",
      "cleaned OVS.csv\n",
      "cleaned SCHP.csv\n",
      "cleaned JKJ.csv\n",
      "cleaned RNDV.csv\n",
      "cleaned SDP.csv\n",
      "cleaned GIGB.csv\n",
      "cleaned IGHG.csv\n",
      "cleaned SCHG.csv\n",
      "cleaned FTCS.csv\n",
      "cleaned ILTB.csv\n",
      "cleaned PFFR.csv\n",
      "cleaned ULST.csv\n",
      "cleaned XLP.csv\n",
      "cleaned TDTF.csv\n",
      "cleaned DUSL.csv\n",
      "cleaned BSMM.csv\n",
      "cleaned IBMO.csv\n",
      "cleaned XLG.csv\n",
      "cleaned MLPY.csv\n",
      "cleaned FTXN.csv\n",
      "cleaned IG.csv\n",
      "cleaned IEFN.csv\n",
      "cleaned BSCQ.csv\n",
      "cleaned NUBD.csv\n",
      "cleaned PTBD.csv\n",
      "cleaned AMUB.csv\n",
      "cleaned HDG.csv\n",
      "cleaned PBE.csv\n",
      "cleaned SPHY.csv\n",
      "cleaned RXI.csv\n",
      "cleaned ISMD.csv\n",
      "cleaned SLYV.csv\n",
      "cleaned RZV.csv\n",
      "cleaned WBIG.csv\n",
      "cleaned CACG.csv\n",
      "cleaned COMT.csv\n",
      "cleaned IAK.csv\n",
      "cleaned EVX.csv\n",
      "cleaned FWDB.csv\n",
      "cleaned EWK.csv\n",
      "cleaned USDY.csv\n",
      "cleaned USRT.csv\n",
      "cleaned GXF.csv\n",
      "cleaned KBWD.csv\n",
      "cleaned NAIL.csv\n",
      "cleaned PZT.csv\n",
      "cleaned USSG.csv\n",
      "cleaned IWF.csv\n",
      "cleaned IYM.csv\n",
      "cleaned PWS.csv\n",
      "cleaned PTH.csv\n",
      "cleaned KBE.csv\n",
      "cleaned IYZ.csv\n",
      "cleaned COWZ.csv\n",
      "cleaned ROOF.csv\n",
      "cleaned FIVG.csv\n",
      "cleaned EWCO.csv\n",
      "cleaned KCE.csv\n",
      "cleaned GVI.csv\n",
      "cleaned MDIV.csv\n",
      "cleaned BBUS.csv\n",
      "cleaned ISTB.csv\n",
      "cleaned TGRW.csv\n",
      "cleaned IWB.csv\n",
      "cleaned UPW.csv\n",
      "cleaned BSV.csv\n",
      "cleaned XMPT.csv\n",
      "cleaned EWO.csv\n",
      "cleaned WBIT.csv\n",
      "cleaned OUSA.csv\n",
      "cleaned IDNA.csv\n",
      "cleaned SDYL.csv\n",
      "cleaned BSCU.csv\n",
      "cleaned AOM.csv\n",
      "cleaned CLRG.csv\n",
      "cleaned IBMK.csv\n",
      "cleaned CURE.csv\n",
      "cleaned SHAG.csv\n",
      "cleaned WTMF.csv\n",
      "cleaned FDL.csv\n",
      "cleaned XLC.csv\n",
      "cleaned EQWL.csv\n",
      "cleaned TYO.csv\n",
      "cleaned TAIL.csv\n",
      "cleaned DBEH.csv\n",
      "cleaned DIVB.csv\n",
      "cleaned PFFA.csv\n",
      "cleaned PFFV.csv\n",
      "cleaned IBTI.csv\n",
      "cleaned LVHD.csv\n",
      "cleaned AFSM.csv\n",
      "cleaned XVZ.csv\n",
      "cleaned VYM.csv\n",
      "cleaned WFIG.csv\n",
      "cleaned PHDG.csv\n",
      "cleaned SCHB.csv\n",
      "cleaned SDOW.csv\n",
      "cleaned IBTH.csv\n",
      "cleaned DWPP.csv\n",
      "cleaned SMDY.csv\n",
      "cleaned SEF.csv\n",
      "cleaned SJNK.csv\n",
      "cleaned SHV.csv\n",
      "cleaned BJUL.csv\n",
      "cleaned SFYX.csv\n",
      "cleaned CMF.csv\n",
      "cleaned DJD.csv\n",
      "cleaned DIVC.csv\n",
      "cleaned TDTT.csv\n",
      "cleaned FDM.csv\n",
      "cleaned XLB.csv\n",
      "cleaned XLU.csv\n",
      "cleaned FCTR.csv\n",
      "cleaned IBMJ.csv\n",
      "cleaned QED.csv\n",
      "cleaned PSET.csv\n",
      "cleaned FKU.csv\n",
      "cleaned HACK.csv\n",
      "cleaned BSCT.csv\n",
      "cleaned XBI.csv\n",
      "cleaned XAR.csv\n",
      "cleaned DWEQ.csv\n",
      "cleaned RXL.csv\n",
      "cleaned BBMC.csv\n",
      "cleaned RYH.csv\n",
      "cleaned PBW.csv\n",
      "cleaned HYGV.csv\n",
      "cleaned VFMF.csv\n",
      "cleaned IBB.csv\n",
      "cleaned MAAX.csv\n",
      "cleaned ICF.csv\n",
      "cleaned ENTR.csv\n",
      "cleaned ARMR.csv\n",
      "cleaned VTIP.csv\n",
      "cleaned IWC.csv\n",
      "cleaned NFLT.csv\n",
      "cleaned PWV.csv\n",
      "cleaned PUI.csv\n",
      "cleaned QQXT.csv\n",
      "cleaned IYH.csv\n",
      "cleaned PILL.csv\n",
      "cleaned PWC.csv\n",
      "cleaned IYJ.csv\n",
      "cleaned MMLG.csv\n",
      "cleaned LGH.csv\n",
      "cleaned SNUG.csv\n",
      "cleaned IXN.csv\n",
      "cleaned BIL.csv\n",
      "cleaned XMHQ.csv\n",
      "cleaned RCD.csv\n",
      "cleaned PZD.csv\n",
      "cleaned ITM.csv\n",
      "cleaned IWV.csv\n",
      "cleaned IVE.csv\n",
      "cleaned FLDR.csv\n",
      "cleaned FLQS.csv\n",
      "cleaned RTM.csv\n",
      "cleaned EWL.csv\n",
      "cleaned RYJ.csv\n",
      "cleaned ONEO.csv\n",
      "cleaned CVY.csv\n",
      "cleaned MLPI.csv\n",
      "cleaned HOMZ.csv\n",
      "cleaned VOT.csv\n",
      "cleaned MYY.csv\n",
      "cleaned PAWZ.csv\n",
      "cleaned SQLV.csv\n",
      "cleaned MVV.csv\n",
      "cleaned IBND.csv\n",
      "cleaned HDGE.csv\n",
      "cleaned HMOP.csv\n",
      "cleaned DIVA.csv\n",
      "cleaned AMLP.csv\n",
      "cleaned BJUN.csv\n",
      "cleaned IPFF.csv\n",
      "cleaned VTI.csv\n",
      "cleaned IBTJ.csv\n",
      "cleaned TBF.csv\n",
      "cleaned FCOM.csv\n",
      "cleaned PAMC.csv\n",
      "cleaned QGRO.csv\n",
      "cleaned DFE.csv\n",
      "cleaned DDM.csv\n",
      "cleaned IBUY.csv\n",
      "cleaned FFSG.csv\n",
      "cleaned OVB.csv\n",
      "cleaned FDHY.csv\n",
      "cleaned SCHA.csv\n",
      "cleaned AVUS.csv\n",
      "cleaned LDUR.csv\n",
      "cleaned IIGV.csv\n",
      "cleaned JKL.csv\n",
      "cleaned SCHV.csv\n",
      "cleaned MLN.csv\n",
      "cleaned IBTK.csv\n",
      "cleaned GNMA.csv\n",
      "cleaned XNTK.csv\n",
      "cleaned CLIX.csv\n",
      "cleaned CNRG.csv\n",
      "cleaned XME.csv\n",
      "cleaned VBR.csv\n",
      "cleaned FDN.csv\n",
      "cleaned XLV.csv\n",
      "cleaned TZA.csv\n",
      "cleaned DRV.csv\n",
      "cleaned POTX.csv\n",
      "cleaned VNQ.csv\n",
      "cleaned BDCZ.csv\n",
      "cleaned HDV.csv\n",
      "cleaned QID.csv\n",
      "cleaned DWFI.csv\n",
      "cleaned FTXH.csv\n",
      "cleaned LQD.csv\n",
      "cleaned MOAT.csv\n",
      "cleaned GHYB.csv\n",
      "cleaned ONEY.csv\n",
      "cleaned RZG.csv\n",
      "cleaned SLYG.csv\n",
      "cleaned GSLC.csv\n",
      "cleaned AUSF.csv\n",
      "cleaned DFEN.csv\n",
      "cleaned SPGP.csv\n",
      "cleaned KBWB.csv\n",
      "cleaned FENY.csv\n",
      "cleaned UFO.csv\n",
      "cleaned SPSB.csv\n",
      "cleaned CATH.csv\n",
      "cleaned JMBS.csv\n",
      "cleaned KNAB.csv\n",
      "cleaned XSMO.csv\n",
      "cleaned ARCM.csv\n",
      "cleaned ABEQ.csv\n",
      "cleaned IYK.csv\n",
      "cleaned PWB.csv\n",
      "cleaned BYLD.csv\n",
      "cleaned IYF.csv\n",
      "cleaned QTEC.csv\n",
      "cleaned BKSB.csv\n",
      "cleaned FLIY.csv\n",
      "cleaned FLGR.csv\n",
      "cleaned ITA.csv\n",
      "cleaned FLGE.csv\n",
      "cleaned IWM.csv\n",
      "cleaned FLSW.csv\n",
      "cleaned UST.csv\n",
      "cleaned MMTM.csv\n",
      "cleaned RWM.csv\n",
      "cleaned SYLD.csv\n",
      "cleaned TERM.csv\n",
      "cleaned RYF.csv\n",
      "cleaned WBIL.csv\n",
      "cleaned OEUR.csv\n",
      "cleaned RNSC.csv\n",
      "cleaned VLUE.csv\n",
      "cleaned VOO.csv\n",
      "cleaned TADS.csv\n",
      "cleaned AMJ.csv\n",
      "cleaned VOX.csv\n",
      "cleaned MLPE.csv\n",
      "cleaned FTXR.csv\n",
      "cleaned BSCM.csv\n",
      "cleaned BSMQ.csv\n",
      "cleaned FCVT.csv\n",
      "cleaned PAVE.csv\n",
      "cleaned BAPR.csv\n",
      "cleaned CZA.csv\n",
      "cleaned PY.csv\n",
      "cleaned MEAR.csv\n",
      "cleaned HTAB.csv\n",
      "cleaned RETL.csv\n",
      "cleaned EFNL.csv\n",
      "cleaned REVS.csv\n",
      "cleaned IBTF.csv\n",
      "cleaned VXF.csv\n",
      "cleaned URTH.csv\n",
      "cleaned SCHM.csv\n",
      "cleaned SMDV.csv\n",
      "cleaned SSLY.csv\n",
      "cleaned IBTG.csv\n",
      "cleaned SCHZ.csv\n",
      "cleaned DES.csv\n",
      "cleaned SHY.csv\n",
      "cleaned VIRS.csv\n",
      "cleaned DIG.csv\n",
      "cleaned SIJ.csv\n",
      "cleaned FALN.csv\n",
      "cleaned BSMP.csv\n",
      "cleaned NUMV.csv\n",
      "cleaned JUST.csv\n",
      "cleaned BSCL.csv\n",
      "cleaned IBBJ.csv\n",
      "cleaned NRGD.csv\n",
      "cleaned HOLD.csv\n",
      "cleaned ESCR.csv\n",
      "cleaned TOKE.csv\n",
      "cleaned FTXD.csv\n",
      "cleaned DSI.csv\n",
      "cleaned MILN.csv\n",
      "cleaned RECS.csv\n",
      "cleaned VLU.csv\n",
      "cleaned KLCD.csv\n",
      "cleaned HYDB.csv\n",
      "cleaned SEPZ.csv\n",
      "cleaned SPHD.csv\n",
      "cleaned WLDR.csv\n",
      "cleaned USHG.csv\n",
      "cleaned EVSTC.csv\n",
      "cleaned WEBL.csv\n",
      "cleaned FINX.csv\n",
      "cleaned UVXY.csv\n",
      "cleaned DFEB.csv\n",
      "cleaned RWL.csv\n",
      "cleaned HELX.csv\n",
      "cleaned IUS.csv\n",
      "cleaned TBND.csv\n",
      "cleaned CMBS.csv\n",
      "cleaned IWL.csv\n",
      "cleaned KBWY.csv\n",
      "cleaned GVIP.csv\n",
      "cleaned FRLG.csv\n",
      "cleaned IYG.csv\n",
      "cleaned GTO.csv\n",
      "cleaned BIV.csv\n",
      "cleaned IXC.csv\n",
      "cleaned IYE.csv\n",
      "cleaned UJB.csv\n",
      "cleaned JMOM.csv\n",
      "cleaned IYR.csv\n",
      "cleaned AUGZ.csv\n",
      "cleaned SRET.csv\n",
      "cleaned CCON.csv\n",
      "cleaned ITB.csv\n",
      "cleaned IWY.csv\n",
      "cleaned DDIV.csv\n",
      "cleaned IWN.csv\n",
      "cleaned VFVA.csv\n",
      "cleaned UGE.csv\n",
      "cleaned WIL.csv\n",
      "cleaned IAT.csv\n",
      "cleaned EWC.csv\n",
      "cleaned FLRG.csv\n",
      "cleaned GTIP.csv\n",
      "cleaned SPIB.csv\n",
      "cleaned FNGS.csv\n",
      "cleaned GAL.csv\n",
      "cleaned HEWG.csv\n",
      "cleaned DALI.csv\n",
      "cleaned HYDW.csv\n",
      "cleaned SPHQ.csv\n",
      "cleaned FNGD.csv\n",
      "cleaned OUSM.csv\n",
      "cleaned RYE.csv\n",
      "cleaned MZZ.csv\n",
      "cleaned BSCN.csv\n",
      "cleaned AOA.csv\n",
      "cleaned VBK.csv\n",
      "cleaned HTUS.csv\n",
      "cleaned MUB.csv\n",
      "cleaned VGIT.csv\n",
      "cleaned ESML.csv\n",
      "cleaned PQSV.csv\n",
      "cleaned NULG.csv\n",
      "cleaned IBMP.csv\n",
      "cleaned PTMC.csv\n",
      "cleaned BSMR.csv\n",
      "cleaned TMF.csv\n",
      "cleaned FPE.csv\n",
      "cleaned IBTE.csv\n",
      "cleaned SCHX.csv\n",
      "cleaned HDIV.csv\n",
      "cleaned FDIS.csv\n",
      "cleaned DEF.csv\n",
      "cleaned SCHO.csv\n",
      "cleaned OVL.csv\n",
      "cleaned XVV.csv\n",
      "cleaned OVM.csv\n",
      "cleaned MOM.csv\n",
      "cleaned LTPZ.csv\n",
      "cleaned SDY.csv\n",
      "cleaned STIP.csv\n",
      "cleaned TCHP.csv\n",
      "cleaned TMFC.csv\n",
      "cleaned JPUS.csv\n",
      "cleaned WFHY.csv\n",
      "cleaned IBTD.csv\n",
      "cleaned FTLB.csv\n",
      "cleaned SHYL.csv\n",
      "cleaned EAGG.csv\n",
      "cleaned EQAL.csv\n",
      "cleaned TLT.csv\n",
      "cleaned DIVO.csv\n",
      "cleaned FOVL.csv\n",
      "cleaned SHM.csv\n",
      "cleaned IBMQ.csv\n",
      "cleaned BSMS.csv\n",
      "cleaned TDVG.csv\n",
      "cleaned IEIH.csv\n",
      "cleaned SDVY.csv\n",
      "cleaned MBSD.csv\n",
      "cleaned ACT.csv\n",
      "cleaned DURA.csv\n",
      "cleaned FGM.csv\n",
      "cleaned FV.csv\n",
      "cleaned REML.csv\n",
      "cleaned XLY.csv\n",
      "cleaned BSCO.csv\n",
      "cleaned SSG.csv\n",
      "cleaned MLPG.csv\n",
      "cleaned CWS.csv\n",
      "cleaned DRN.csv\n",
      "cleaned BOSS.csv\n",
      "cleaned FTXG.csv\n",
      "cleaned ANGL.csv\n",
      "cleaned WBIN.csv\n",
      "cleaned CHEP.csv\n",
      "cleaned HNDL.csv\n",
      "cleaned WBIY.csv\n",
      "cleaned ONEV.csv\n",
      "cleaned VCSH.csv\n",
      "cleaned CHGX.csv\n",
      "cleaned NORW.csv\n",
      "cleaned SWAN.csv\n",
      "cleaned URE.csv\n",
      "cleaned WIZ.csv\n",
      "cleaned PYPE.csv\n",
      "cleaned SLVP.csv\n",
      "cleaned EWU.csv\n",
      "cleaned IWO.csv\n",
      "cleaned QARP.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned SPSM.csv\n",
      "cleaned IWX.csv\n",
      "cleaned RFDA.csv\n",
      "cleaned BIB.csv\n",
      "cleaned PWZ.csv\n",
      "cleaned PVI.csv\n",
      "cleaned IYW.csv\n",
      "cleaned RAAX.csv\n",
      "cleaned ROM.csv\n",
      "cleaned PEXL.csv\n",
      "cleaned PXQ.csv\n",
      "cleaned PBSM.csv\n",
      "cleaned JDIV.csv\n",
      "cleaned VSMV.csv\n",
      "cleaned SGDM.csv\n",
      "cleaned PLC.csv\n",
      "cleaned USEP.csv\n",
      "cleaned LRGF.csv\n",
      "cleaned BKHY.csv\n",
      "cleaned FLRU.csv\n",
      "cleaned RWK.csv\n",
      "cleaned EWQ.csv\n",
      "cleaned MTUM.csv\n",
      "cleaned RXD.csv\n",
      "cleaned EZA.csv\n",
      "cleaned GDMA.csv\n",
      "cleaned SPIP.csv\n",
      "cleaned HEWU.csv\n",
      "cleaned HUSV.csv\n",
      "cleaned MLPC.csv\n",
      "cleaned QYLG.csv\n",
      "cleaned LSAF.csv\n",
      "cleaned BSCK.csv\n",
      "cleaned TAEQ.csv\n",
      "cleaned TUR.csv\n",
      "cleaned TWM.csv\n",
      "cleaned TFLO.csv\n",
      "cleaned DUSA.csv\n",
      "cleaned FFHG.csv\n",
      "cleaned THCX.csv\n",
      "cleaned HSRT.csv\n",
      "cleaned VUG.csv\n",
      "cleaned VTC.csv\n",
      "cleaned FCAL.csv\n",
      "cleaned DHS.csv\n",
      "cleaned TOK.csv\n",
      "cleaned DDG.csv\n",
      "cleaned PFIG.csv\n",
      "cleaned FDIV.csv\n",
      "cleaned XTL.csv\n",
      "cleaned SCHJ.csv\n",
      "cleaned FMAT.csv\n",
      "cleaned VGSH.csv\n",
      "cleaned JKG.csv\n",
      "cleaned URTY.csv\n",
      "cleaned EVLMC.csv\n",
      "cleaned JKF.csv\n",
      "cleaned IBTA.csv\n",
      "cleaned SCHK.csv\n",
      "cleaned SFYF.csv\n",
      "cleaned DIV.csv\n",
      "cleaned FRI.csv\n",
      "cleaned QQH.csv\n",
      "cleaned WOMN.csv\n",
      "cleaned VEGN.csv\n",
      "cleaned DIA.csv\n",
      "cleaned FSZ.csv\n",
      "cleaned YOLO.csv\n",
      "cleaned QUAL.csv\n",
      "cleaned AMZA.csv\n",
      "cleaned ACWI.csv\n",
      "cleaned NUMG.csv\n",
      "cleaned XOP.csv\n",
      "cleaned XLK.csv\n",
      "cleaned PTLC.csv\n",
      "cleaned NULC.csv\n",
      "cleaned FDD.csv\n",
      "cleaned FFIU.csv\n",
      "cleaned AOR.csv\n",
      "cleaned NRGU.csv\n",
      "cleaned DYHG.csv\n",
      "cleaned MLPB.csv\n",
      "cleaned SPY.csv\n",
      "cleaned VFMO.csv\n",
      "cleaned RDIV.csv\n",
      "cleaned SPHB.csv\n",
      "cleaned UCON.csv\n",
      "cleaned HYGH.csv\n",
      "cleaned HEWC.csv\n",
      "cleaned DVOL.csv\n",
      "cleaned BBCA.csv\n",
      "cleaned HYHG.csv\n",
      "cleaned SNLN.csv\n",
      "cleaned EWP.csv\n",
      "cleaned RWJ.csv\n",
      "cleaned USDU.csv\n",
      "cleaned USD.csv\n",
      "cleaned PNQI.csv\n",
      "cleaned SPDV.csv\n",
      "cleaned USEQ.csv\n",
      "cleaned EWG.csv\n",
      "cleaned ROUS.csv\n",
      "cleaned IHAK.csv\n",
      "cleaned VCIT.csv\n",
      "cleaned FLGB.csv\n",
      "cleaned XSLV.csv\n",
      "cleaned FIXD.csv\n",
      "cleaned JHSC.csv\n",
      "cleaned TIPX.csv\n",
      "cleaned BKSE.csv\n",
      "cleaned IXP.csv\n",
      "cleaned PTF.csv\n",
      "cleaned FITE.csv\n",
      "cleaned VCEB.csv\n",
      "cleaned IYT.csv\n",
      "cleaned TIPZ.csv\n",
      "cleaned FBGX.csv\n",
      "cleaned IYC.csv\n",
      "cleaned TPSC.csv\n",
      "cleaned PXE.csv\n",
      "cleaned FLEH.csv\n",
      "cleaned LRGE.csv\n",
      "cleaned PLW.csv\n",
      "cleaned FLQM.csv\n",
      "cleaned GBF.csv\n",
      "cleaned WBII.csv\n",
      "cleaned DVLU.csv\n",
      "cleaned XSVM.csv\n",
      "cleaned CALF.csv\n",
      "cleaned FNGU.csv\n",
      "cleaned ONEQ.csv\n",
      "cleaned RYT.csv\n",
      "cleaned USIG.csv\n",
      "cleaned QYLD.csv\n",
      "cleaned KSCD.csv\n",
      "cleaned SRS.csv\n",
      "cleaned JPME.csv\n",
      "cleaned PQSG.csv\n",
      "cleaned BSMT.csv\n",
      "cleaned XLI.csv\n",
      "cleaned NULV.csv\n",
      "cleaned OLD.csv\n",
      "cleaned DBEU.csv\n",
      "cleaned SJB.csv\n",
      "cleaned SKF.csv\n",
      "cleaned RWGV.csv\n",
      "cleaned SCHI.csv\n",
      "cleaned TBX.csv\n",
      "cleaned JKD.csv\n",
      "cleaned DEW.csv\n",
      "cleaned AMCA.csv\n",
      "cleaned IBTB.csv\n",
      "cleaned JKE.csv\n",
      "cleaned TAPR.csv\n",
      "cleaned NIFE.csv\n",
      "cleaned FTLS.csv\n",
      "cleaned XTN.csv\n",
      "cleaned FCOR.csv\n",
      "cleaned VBND.csv\n",
      "cleaned BFOR.csv\n",
      "cleaned SMDD.csv\n",
      "cleaned SCHH.csv\n",
      "cleaned TMV.csv\n",
      "cleaned VTV.csv\n",
      "cleaned FCAN.csv\n",
      "cleaned WCLD.csv\n",
      "cleaned VAW.csv\n",
      "cleaned IGSB.csv\n",
      "cleaned LSLT.csv\n",
      "cleaned FDG.csv\n",
      "cleaned DUST.csv\n",
      "cleaned TYD.csv\n",
      "cleaned ESNG.csv\n",
      "cleaned BSMU.csv\n",
      "cleaned CIBR.csv\n",
      "cleaned FFEB.csv\n",
      "cleaned VNLA.csv\n",
      "cleaned TTT.csv\n",
      "cleaned FIW.csv\n",
      "cleaned MINC.csv\n",
      "cleaned BDCS.csv\n",
      "cleaned MLPA.csv\n",
      "cleaned NEED.csv\n",
      "cleaned CWB.csv\n",
      "cleaned NUAG.csv\n",
      "cleaned IEDI.csv\n",
      "cleaned YLDE.csv\n",
      "cleaned RYU.csv\n",
      "cleaned PBJ.csv\n",
      "cleaned HIBL.csv\n",
      "cleaned FNDX.csv\n",
      "cleaned IOO.csv\n",
      "cleaned FLQL.csv\n",
      "cleaned EWD.csv\n",
      "cleaned FLFR.csv\n",
      "cleaned UOCT.csv\n",
      "cleaned UDN.csv\n",
      "cleaned FLGV.csv\n",
      "cleaned BIS.csv\n",
      "cleaned KNOW.csv\n",
      "cleaned ENOR.csv\n",
      "cleaned FLHY.csv\n",
      "cleaned NACP.csv\n",
      "cleaned SPYX.csv\n",
      "cleaned YYY.csv\n",
      "cleaned FLLV.csv\n",
      "cleaned XMLV.csv\n",
      "cleaned FBCV.csv\n",
      "cleaned GFIN.csv\n",
      "cleaned REK.csv\n",
      "cleaned NOBL.csv\n",
      "cleaned LNGR.csv\n",
      "cleaned RFG.csv\n",
      "cleaned RODI.csv\n",
      "cleaned JHMA.csv\n",
      "cleaned ALTY.csv\n",
      "cleaned PKB.csv\n",
      "cleaned ERX.csv\n",
      "cleaned BKLC.csv\n",
      "cleaned UTES.csv\n",
      "cleaned IFRA.csv\n",
      "cleaned FNCL.csv\n",
      "cleaned IJS.csv\n",
      "cleaned TUSA.csv\n",
      "cleaned CSM.csv\n",
      "cleaned DWAT.csv\n",
      "cleaned KCNY.csv\n",
      "cleaned JIGB.csv\n",
      "cleaned CNBS.csv\n",
      "cleaned SYE.csv\n",
      "cleaned EVGBC.csv\n",
      "cleaned FMHI.csv\n",
      "cleaned QUS.csv\n",
      "cleaned FXN.csv\n",
      "cleaned SMCP.csv\n",
      "cleaned EAOM.csv\n",
      "cleaned IETC.csv\n",
      "cleaned SOXX.csv\n",
      "cleaned JPSE.csv\n",
      "cleaned ADME.csv\n",
      "cleaned PQLC.csv\n",
      "cleaned OCIO.csv\n",
      "cleaned GUSH.csv\n",
      "cleaned INDS.csv\n",
      "cleaned FXO.csv\n",
      "cleaned FVD.csv\n",
      "cleaned HYS.csv\n",
      "cleaned RNLC.csv\n",
      "cleaned HYD.csv\n",
      "cleaned VRP.csv\n",
      "cleaned FMIL.csv\n",
      "cleaned VUSE.csv\n",
      "cleaned FAZ.csv\n",
      "cleaned MIDF.csv\n",
      "cleaned JPHY.csv\n",
      "cleaned NUHY.csv\n",
      "cleaned SQEW.csv\n",
      "cleaned DTN.csv\n",
      "cleaned PLAT.csv\n",
      "cleaned SKYY.csv\n",
      "cleaned ITOT.csv\n",
      "cleaned IJR.csv\n",
      "cleaned LRNZ.csv\n",
      "cleaned ERY.csv\n",
      "cleaned MDYV.csv\n",
      "cleaned PJP.csv\n",
      "cleaned BUL.csv\n",
      "cleaned ONLN.csv\n",
      "cleaned PHO.csv\n",
      "cleaned RSP.csv\n",
      "cleaned IVOV.csv\n",
      "cleaned SPTI.csv\n",
      "cleaned SIXH.csv\n",
      "cleaned FLCO.csv\n",
      "cleaned ZROZ.csv\n",
      "cleaned CSML.csv\n",
      "cleaned MARB.csv\n",
      "cleaned PUTW.csv\n",
      "cleaned SNPE.csv\n",
      "cleaned UJUL.csv\n",
      "cleaned TPYP.csv\n",
      "cleaned PSR.csv\n",
      "cleaned BNKU.csv\n",
      "cleaned UJUN.csv\n",
      "cleaned EINC.csv\n",
      "cleaned TECS.csv\n",
      "cleaned PSP.csv\n",
      "cleaned JMIN.csv\n",
      "cleaned BND.csv\n",
      "cleaned ARKK.csv\n",
      "cleaned BBP.csv\n",
      "cleaned AWTM.csv\n",
      "cleaned EDV.csv\n",
      "cleaned UTRN.csv\n",
      "cleaned IQM.csv\n",
      "cleaned AGGP.csv\n",
      "cleaned MAGA.csv\n",
      "cleaned ROSC.csv\n",
      "cleaned EUFN.csv\n",
      "cleaned EPS.csv\n",
      "cleaned USAI.csv\n",
      "cleaned JHMU.csv\n",
      "cleaned BUY.csv\n",
      "cleaned BLHY.csv\n",
      "cleaned PEJ.csv\n",
      "cleaned VTWO.csv\n",
      "cleaned FLYT.csv\n",
      "cleaned PULS.csv\n",
      "cleaned DFND.csv\n",
      "cleaned MFMS.csv\n",
      "cleaned PFF.csv\n",
      "cleaned BKAG.csv\n",
      "cleaned PSCM.csv\n",
      "cleaned NUGT.csv\n",
      "cleaned RISE.csv\n",
      "cleaned VIOO.csv\n",
      "cleaned PCEF.csv\n",
      "cleaned DWAW.csv\n",
      "cleaned DWMC.csv\n",
      "cleaned FBT.csv\n",
      "cleaned PAPR.csv\n",
      "cleaned FCG.csv\n",
      "cleaned XHS.csv\n",
      "cleaned SVXY.csv\n",
      "cleaned ZMLP.csv\n",
      "cleaned CEFS.csv\n",
      "cleaned IPAY.csv\n",
      "cleaned CLOU.csv\n",
      "cleaned SMOG.csv\n",
      "cleaned DBV.csv\n",
      "cleaned CFO.csv\n",
      "cleaned FSMB.csv\n",
      "cleaned SOXL.csv\n",
      "cleaned DPST.csv\n",
      "cleaned FXZ.csv\n",
      "cleaned FDMO.csv\n",
      "cleaned IEUS.csv\n",
      "cleaned FTHI.csv\n",
      "cleaned IEUR.csv\n",
      "cleaned SAA.csv\n",
      "cleaned DWUS.csv\n",
      "cleaned SQQQ.csv\n",
      "cleaned FXL.csv\n",
      "cleaned SBM.csv\n",
      "cleaned FFTY.csv\n",
      "cleaned OMFL.csv\n",
      "cleaned DOG.csv\n",
      "cleaned SMB.csv\n",
      "cleaned ZCAN.csv\n",
      "cleaned LABD.csv\n",
      "cleaned VO.csv\n",
      "cleaned LFEQ.csv\n",
      "cleaned HYG.csv\n",
      "cleaned PSMG.csv\n",
      "cleaned HTRB.csv\n",
      "cleaned SYG.csv\n",
      "cleaned ECOZ.csv\n",
      "cleaned XHE.csv\n",
      "cleaned FSTA.csv\n",
      "cleaned SZK.csv\n",
      "cleaned QLD.csv\n",
      "cleaned XLRE.csv\n",
      "cleaned JPGB.csv\n",
      "cleaned GUDB.csv\n",
      "cleaned QLS.csv\n",
      "cleaned BMLP.csv\n",
      "cleaned REGL.csv\n",
      "cleaned RDOG.csv\n",
      "cleaned VAMO.csv\n",
      "cleaned RVRS.csv\n",
      "cleaned IEI.csv\n",
      "cleaned JHMT.csv\n",
      "cleaned IGV.csv\n",
      "cleaned ALTL.csv\n",
      "cleaned EUDG.csv\n",
      "cleaned PKW.csv\n",
      "cleaned XMVM.csv\n",
      "cleaned BUFF.csv\n",
      "cleaned JHMC.csv\n",
      "cleaned FLTR.csv\n",
      "cleaned ERM.csv\n",
      "cleaned GSEW.csv\n",
      "cleaned SRLN.csv\n",
      "cleaned SPVU.csv\n",
      "cleaned EES.csv\n",
      "cleaned HYZD.csv\n",
      "cleaned FBND.csv\n",
      "cleaned XOUT.csv\n",
      "cleaned PSQ.csv\n",
      "cleaned FISR.csv\n",
      "cleaned PRF.csv\n",
      "cleaned FREL.csv\n",
      "cleaned FBCG.csv\n",
      "cleaned REZ.csv\n",
      "cleaned LGOV.csv\n",
      "cleaned REM.csv\n",
      "cleaned RFV.csv\n",
      "cleaned BIBL.csv\n",
      "cleaned FLBL.csv\n",
      "cleaned SLQD.csv\n",
      "cleaned TILT.csv\n",
      "cleaned GOVT.csv\n",
      "cleaned QVAL.csv\n",
      "cleaned IGE.csv\n",
      "cleaned SILJ.csv\n",
      "cleaned DMRS.csv\n",
      "cleaned IEZ.csv\n",
      "cleaned GSIG.csv\n",
      "cleaned PEX.csv\n",
      "cleaned PBND.csv\n",
      "cleaned UMDD.csv\n",
      "cleaned UJAN.csv\n",
      "cleaned AESR.csv\n",
      "cleaned IBDN.csv\n",
      "cleaned FHLC.csv\n",
      "cleaned PSCH.csv\n",
      "cleaned XLSR.csv\n",
      "cleaned BOUT.csv\n",
      "cleaned BSJP.csv\n",
      "cleaned OIH.csv\n",
      "cleaned UPRO.csv\n",
      "cleaned PSMC.csv\n",
      "cleaned GBIL.csv\n",
      "cleaned FVC.csv\n",
      "cleaned MGV.csv\n",
      "cleaned DEED.csv\n",
      "cleaned NUSC.csv\n",
      "cleaned DGRO.csv\n",
      "cleaned NETL.csv\n",
      "cleaned ZIG.csv\n",
      "cleaned EAOK.csv\n",
      "cleaned FXH.csv\n",
      "cleaned JPST.csv\n",
      "cleaned KOCT.csv\n",
      "cleaned RIGS.csv\n",
      "cleaned CDC.csv\n",
      "cleaned FDLO.csv\n",
      "cleaned SLT.csv\n",
      "cleaned DLN.csv\n",
      "cleaned SDGA.csv\n",
      "cleaned INKM.csv\n",
      "cleaned FCEF.csv\n",
      "cleaned TTAC.csv\n",
      "cleaned OSCV.csv\n",
      "cleaned TFIV.csv\n",
      "cleaned PSMB.csv\n",
      "cleaned FDVV.csv\n",
      "cleaned BSJQ.csv\n",
      "cleaned AGZ.csv\n",
      "cleaned XJH.csv\n",
      "cleaned AIQ.csv\n",
      "cleaned QLV.csv\n",
      "cleaned PSCI.csv\n",
      "cleaned IBDO.csv\n",
      "cleaned EMNT.csv\n",
      "cleaned DWAS.csv\n",
      "cleaned CLTL.csv\n",
      "cleaned RFUN.csv\n",
      "cleaned IJT.csv\n",
      "cleaned PGF.csv\n",
      "cleaned PEY.csv\n",
      "cleaned SRVR.csv\n",
      "cleaned UUP.csv\n",
      "cleaned JHMF.csv\n",
      "cleaned MDYG.csv\n",
      "cleaned FLUD.csv\n",
      "cleaned IVOG.csv\n",
      "cleaned BBC.csv\n",
      "cleaned PST.csv\n",
      "cleaned MMIT.csv\n",
      "cleaned SKOR.csv\n",
      "cleaned GSY.csv\n",
      "cleaned PSC.csv\n",
      "cleaned SPXL.csv\n",
      "cleaned FLMB.csv\n",
      "cleaned BNKD.csv\n",
      "cleaned SPXN.csv\n",
      "cleaned TECB.csv\n",
      "cleaned ROKT.csv\n",
      "cleaned BILS.csv\n",
      "cleaned NYF.csv\n",
      "cleaned SPTM.csv\n",
      "cleaned UTSL.csv\n",
      "cleaned XDIV.csv\n",
      "cleaned DFVS.csv\n",
      "cleaned IPO.csv\n",
      "cleaned MFUS.csv\n",
      "cleaned JSMD.csv\n",
      "cleaned NANR.csv\n",
      "cleaned FUMB.csv\n",
      "cleaned SIXL.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned JHMS.csv\n",
      "cleaned FLTB.csv\n",
      "cleaned UWM.csv\n",
      "cleaned IGF.csv\n",
      "cleaned PIO.csv\n",
      "cleaned SPMO.csv\n",
      "cleaned AIEQ.csv\n",
      "cleaned IHI.csv\n",
      "cleaned KRE.csv\n",
      "cleaned KSA.csv\n",
      "cleaned DYNF.csv\n",
      "cleaned QLC.csv\n",
      "cleaned IBDM.csv\n",
      "cleaned REET.csv\n",
      "cleaned CNCR.csv\n",
      "cleaned BSJS.csv\n",
      "cleaned XHB.csv\n",
      "cleaned SFHY.csv\n",
      "cleaned FTSD.csv\n",
      "cleaned PTIN.csv\n",
      "cleaned MIDU.csv\n",
      "cleaned DEEP.csv\n",
      "cleaned MDY.csv\n",
      "cleaned RNMC.csv\n",
      "cleaned LQDH.csv\n",
      "cleaned QVM.csv\n",
      "cleaned JNK.csv\n",
      "cleaned STOT.csv\n",
      "cleaned FFTI.csv\n",
      "cleaned FYX.csv\n",
      "cleaned FSMD.csv\n",
      "cleaned TDIV.csv\n",
      "cleaned HSMV.csv\n",
      "cleaned LSST.csv\n",
      "cleaned IGLB.csv\n",
      "cleaned XT.csv\n",
      "cleaned ACIO.csv\n",
      "cleaned NURE.csv\n",
      "cleaned XRLV.csv\n",
      "cleaned NUSA.csv\n",
      "cleaned LQDI.csv\n",
      "cleaned FJNK.csv\n",
      "cleaned LABU.csv\n",
      "cleaned MGC.csv\n",
      "cleaned THY.csv\n",
      "cleaned IGBH.csv\n",
      "cleaned VGT.csv\n",
      "cleaned TCTL.csv\n",
      "cleaned SYV.csv\n",
      "cleaned IEME.csv\n",
      "cleaned AFLG.csv\n",
      "cleaned BSJR.csv\n",
      "cleaned AFMC.csv\n",
      "cleaned EDEN.csv\n",
      "cleaned GBGR.csv\n",
      "cleaned FMK.csv\n",
      "cleaned XES.csv\n",
      "cleaned SUB.csv\n",
      "cleaned IBDL.csv\n",
      "cleaned SRTY.csv\n",
      "cleaned SUSL.csv\n",
      "cleaned PEZ.csv\n",
      "cleaned TPLC.csv\n",
      "cleaned UYG.csv\n",
      "cleaned EUDV.csv\n",
      "cleaned JHME.csv\n",
      "cleaned QQEW.csv\n",
      "cleaned IEO.csv\n",
      "cleaned BKMC.csv\n",
      "cleaned QQQE.csv\n",
      "cleaned JQUA.csv\n",
      "cleaned SIZE.csv\n",
      "cleaned SPTL.csv\n",
      "cleaned SBIO.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPXB</th>\n",
       "      <th>PSM</th>\n",
       "      <th>SPXU</th>\n",
       "      <th>PPA</th>\n",
       "      <th>USTB</th>\n",
       "      <th>XSHD</th>\n",
       "      <th>BBSA</th>\n",
       "      <th>BBRE</th>\n",
       "      <th>TRND</th>\n",
       "      <th>QDIV</th>\n",
       "      <th>...</th>\n",
       "      <th>EUDV</th>\n",
       "      <th>JHME</th>\n",
       "      <th>QQEW</th>\n",
       "      <th>IEO</th>\n",
       "      <th>BKMC</th>\n",
       "      <th>QQQE</th>\n",
       "      <th>JQUA</th>\n",
       "      <th>SIZE</th>\n",
       "      <th>SPTL</th>\n",
       "      <th>SBIO</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-02-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-03-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-04-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-05-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  1550 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            SPXB  PSM  SPXU  PPA  USTB  XSHD  BBSA  BBRE  TRND  QDIV  ...  \\\n",
       "Date                                                                  ...   \n",
       "1980-01-01   NaN  NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "1980-02-01   NaN  NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "1980-03-01   NaN  NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "1980-04-01   NaN  NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "1980-05-01   NaN  NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "\n",
       "            EUDV  JHME  QQEW  IEO  BKMC  QQQE  JQUA  SIZE  SPTL  SBIO  \n",
       "Date                                                                   \n",
       "1980-01-01   NaN   NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1980-02-01   NaN   NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1980-03-01   NaN   NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1980-04-01   NaN   NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1980-05-01   NaN   NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 1550 columns]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_cleaned_data()\n",
    "df = df.set_index('Date')\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_amount = 0\n",
    "start_date_time = ''\n",
    "\n",
    "spent_in_purchase_session = 0 # becomes reset each purchase session\n",
    "\n",
    "\n",
    "def find_etfs_and_buy(end_date):\n",
    "    global start_date_time\n",
    "    # filter on etfs to find all ones that have values from 6 months ago\n",
    "    start_date_time = np.datetime64(end_date)\n",
    "    start_filtered = df[df.index == start_date_time.astype(str)]\n",
    "\n",
    "    back_date_time = (\n",
    "            start_date_time.astype('datetime64[M]') - np.timedelta64(3, 'M')\n",
    "        ).astype('datetime64[D]')\n",
    "\n",
    "    back_filtered = df[df.index == back_date_time.astype(str)]\n",
    "    back_filtered = (back_filtered\n",
    "        .reset_index()\n",
    "        .drop(['Date'], axis=1)\n",
    "        .transpose()\n",
    "        .dropna()\n",
    "        .reset_index()\n",
    "        .rename(columns={ 0: 'Start', 'index': 'Ticker' })\n",
    "    )\n",
    "\n",
    "    start_filtered = (start_filtered\n",
    "        .reset_index()\n",
    "        .drop(['Date'], axis=1)\n",
    "        .transpose()\n",
    "        .dropna()\n",
    "        .reset_index()\n",
    "        .rename(columns={ 0: 'End', 'index': 'Ticker' })\n",
    "    )\n",
    "\n",
    "    # discover the percentage changed between \"back\" and \"start\"\n",
    "    merged_filtered = back_filtered.merge(start_filtered, on='Ticker')\n",
    "    merged_filtered['% Changed'] = (merged_filtered['End'] - merged_filtered['Start']) / merged_filtered['Start']\n",
    "\n",
    "    # grab the bottom samples\n",
    "    global etf_samples\n",
    "    global sample_technique\n",
    "    \n",
    "    candidates = None\n",
    "    if sample_technique == 'bottom':\n",
    "        candidates = merged_filtered.sort_values('% Changed', ascending=True).head(etf_samples).reset_index()\n",
    "    elif sample_technique == 'none':\n",
    "        candidates = merged_filtered.head(etf_samples).reset_index()\n",
    "    elif sample_technique == 'top':\n",
    "        candidates = merged_filtered.sort_values('% Changed', ascending=False).head(etf_samples).reset_index()\n",
    "\n",
    "    # model the purchases\n",
    "    global monthly_budget\n",
    "    global purchase_interval\n",
    "    global remaining_amount\n",
    "    global total_spent\n",
    "    global total_months\n",
    "\n",
    "    remaining_amount = monthly_budget * purchase_interval\n",
    "    top_candidate = candidates.iloc[etf_samples - 1]\n",
    "    \n",
    "    global spent_in_purchase_session\n",
    "    spent_in_purchase_session = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    def purchase_candidate(candidate):\n",
    "        global start_date_time\n",
    "        global monthly_budget\n",
    "        global purchase_interval\n",
    "        global etf_samples\n",
    "        global remaining_amount\n",
    "        global total_spent\n",
    "        global total_months\n",
    "        global spent_in_purchase_session\n",
    "        \n",
    "        date = start_date_time.astype(str)\n",
    "        price = row['End']\n",
    "        guid = uuid.uuid1()\n",
    "        \n",
    "        # use calculated amount or remaining_amount => whichever is lower\n",
    "        samples_budget = math.floor((monthly_budget * purchase_interval) / etf_samples)\n",
    "        allowed_budget = min(samples_budget, remaining_amount)\n",
    "        amount = math.floor(allowed_budget / price)\n",
    "        \n",
    "        \n",
    "        if amount < 1:\n",
    "            return\n",
    "        \n",
    "        # make purchase\n",
    "        purchase = {\n",
    "            'id': guid,\n",
    "            'ticker': row['Ticker'],\n",
    "            'amount': amount,\n",
    "            'date': date,\n",
    "            'price': price\n",
    "        }\n",
    "        \n",
    "        # add to portfolio\n",
    "        portfolio[guid] = purchase\n",
    "        \n",
    "        # adjust remaining_amount\n",
    "        remaining_amount -= price * amount\n",
    "        spent_in_purchase_session += price * amount\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    for index, row in candidates.iterrows():\n",
    "        purchase_candidate(row)\n",
    "        \n",
    "    # add remaining budget to candidate if available\n",
    "    if remaining_amount > 0:\n",
    "        purchase_candidate(top_candidate)\n",
    "    \n",
    "    \n",
    "    total_spent += spent_in_purchase_session\n",
    "    total_months += purchase_interval\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def get_roi(start_price, end_price):\n",
    "    return (end_price - start_price) / start_price\n",
    "    \n",
    "\n",
    "# iterate through portfolio and model selling off investments after a minimum of {years_to_sell} years, and after a positive ROI\n",
    "def get_capital_gains():\n",
    "    global portfolio\n",
    "    global roi_threshold\n",
    "    \n",
    "    guids_sold = []\n",
    "    capital_gains = {}\n",
    "    \n",
    "    \n",
    "    purchase_groups = {}\n",
    "    \n",
    "    for guid in portfolio:       \n",
    "        purchase = portfolio[guid]\n",
    "        ticker = purchase['ticker']\n",
    "        start_price = purchase['price']\n",
    "        amount = purchase['amount']\n",
    "        date_purchased = np.datetime64(purchase['date']).astype('datetime64[D]')\n",
    "        \n",
    "        # add {years_to_sell} years\n",
    "        min_sell_date = (\n",
    "            date_purchased.astype('datetime64[Y]') + np.timedelta64(years_to_sell, 'Y')\n",
    "        ).astype('datetime64[D]')\n",
    "        \n",
    "        ticker_df = df[ticker].dropna(how='all')\n",
    "        ticker_sell_df = ticker_df.where(ticker_df >= start_price * roi_threshold).dropna(how='all')\n",
    "        \n",
    "        \n",
    "        if (\n",
    "                min_sell_date < np.datetime64('2020-10-01') and\n",
    "                len(ticker_sell_df.values.tolist()) > 0\n",
    "        ):\n",
    "            available_sell_dates = ticker_sell_df.index.tolist()\n",
    "            available_sell_prices = ticker_sell_df.values.tolist()\n",
    "            \n",
    "            # get the first index in avilable_sell_prices, whose date is after min_sell_date\n",
    "            first_date = available_sell_dates[0]\n",
    "            \n",
    "            sell_index = 0\n",
    "    \n",
    "            # step 1 of sell_index => first available date that it can be sold\n",
    "            while (\n",
    "                sell_index < len(available_sell_dates) and \n",
    "                np.datetime64(available_sell_dates[sell_index]) < min_sell_date\n",
    "            ):\n",
    "                sell_index += 1\n",
    "            \n",
    "            \n",
    "            if sell_index < len(available_sell_dates):\n",
    "                sell_price = available_sell_prices[sell_index]\n",
    "                sell_date = available_sell_dates[sell_index]\n",
    "                \n",
    "                capital_gains[guid] = {\n",
    "                    'id': guid,\n",
    "                    'ticker': ticker,\n",
    "                    'total_amount_spent': amount * start_price,\n",
    "                    'total_amount_sold': amount * sell_price,\n",
    "                    'total_amount_gained': amount * (sell_price - start_price),\n",
    "                    'date_sold': np.datetime64(sell_date).astype('datetime64[D]'),\n",
    "                    'date_purchased': date_purchased\n",
    "                }\n",
    "                guids_sold.append(guid)\n",
    "             \n",
    "            \n",
    "    # remove guids sold\n",
    "    for guid in guids_sold:\n",
    "        if guid in portfolio:\n",
    "            del portfolio[guid]\n",
    "        \n",
    "    \n",
    "    return capital_gains\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "def get_gains():\n",
    "    tickers = []\n",
    "    total_amounts_spent = []\n",
    "    total_amounts_sold = []\n",
    "    total_amounts_gained = []\n",
    "    dates_purchased = []\n",
    "    dates_sold = []\n",
    "    capital_gains = get_capital_gains()\n",
    "\n",
    "    for guid in capital_gains:\n",
    "        item = capital_gains[guid]\n",
    "        ticker = item['ticker']\n",
    "        tickers.append(ticker)\n",
    "        date_purchased = item['date_purchased']\n",
    "        date_sold = item['date_sold']\n",
    "\n",
    "        total_amounts_spent.append(item['total_amount_spent'])\n",
    "        total_amounts_sold.append(item['total_amount_sold'])\n",
    "        total_amounts_gained.append(item['total_amount_gained'])\n",
    "        dates_purchased.append(date_purchased)\n",
    "        dates_sold.append(date_sold)\n",
    "        \n",
    "\n",
    "    df_gains = pd.DataFrame(list(zip(total_amounts_spent, total_amounts_sold, total_amounts_gained, dates_purchased, dates_sold)), index=tickers, columns=['Spent', 'Sold', 'Gained', 'Date Purchased', 'Date Sold'])\n",
    "\n",
    "    df_gains = df_gains.append(pd.Series(df_gains.sum(), name='Totals'))\n",
    "    df_gains['ROI'] = (df_gains['Sold'] - df_gains['Spent']) / df_gains['Spent']\n",
    "    \n",
    "    df_gains['Avg Years Held'] = (df_gains['Date Sold'] - df_gains['Date Purchased']).astype('timedelta64[Y]').astype(str)\n",
    "    return df_gains\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_etf_holdings():\n",
    "    tickers = []\n",
    "    amounts_owned = []\n",
    "\n",
    "    for guid in portfolio:\n",
    "        purchase = portfolio[guid]\n",
    "        ticker = purchase['ticker']\n",
    "        tickers.append(ticker)\n",
    "        amounts_owned.append(purchase['amount'])\n",
    "\n",
    "    \n",
    "    df_remaining = pd.DataFrame(list(zip(amounts_owned)), index=tickers, columns=['Owned'])\n",
    "    df_remaining = df_remaining.reset_index()\n",
    "    df_remaining = df_remaining.rename(columns={ 'index': 'Ticker' })\n",
    "\n",
    "    sr_latest_value = df.iloc[len(df) - 1]\n",
    "    \n",
    "    df_latest_value = pd.DataFrame(sr_latest_value)\n",
    "    df_latest_value = df_latest_value.reset_index()\n",
    "    df_latest_value = df_latest_value.rename(columns={ 'index': 'Ticker' })\n",
    "\n",
    "    df_remaining = df_remaining.merge(df_latest_value, on='Ticker', how='left')\n",
    "    df_remaining['Value'] = df_remaining['Owned'] * df_remaining['2020-09-01']\n",
    "\n",
    "    return df_remaining.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Model Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_currency(value):\n",
    "    return '{:,.2f}'.format(value)\n",
    "\n",
    "\n",
    "def get_results():\n",
    "    # model making purchases over course of 15 years\n",
    "    global start_date\n",
    "    global purchase_interval\n",
    "    dates = np.arange(\n",
    "        np.datetime64(start_date),\n",
    "        np.datetime64('now'),\n",
    "        np.timedelta64(purchase_interval, 'M'),\n",
    "        dtype='datetime64[M]'\n",
    "    ).astype('datetime64[D]').astype(str)\n",
    "\n",
    "    months_of_purchase = len(dates)\n",
    "\n",
    "    for date in dates:\n",
    "        find_etfs_and_buy(date)\n",
    "\n",
    "\n",
    "    df_gains = get_gains()\n",
    "    df_etf_holdings = get_etf_holdings()\n",
    "    \n",
    "    \n",
    "    def keep_etf_index(index):\n",
    "        return index != 'Totals'\n",
    "\n",
    "    filtered_index = list(filter(keep_etf_index, df_gains.index.tolist()))\n",
    "    \n",
    "    # calculate avg_years_held\n",
    "    df_gains['Avg Years Held'].loc['Totals'] = 0\n",
    "    df_gains['Avg Years Held'] = pd.to_numeric(df_gains['Avg Years Held'])\n",
    "    avg_years_held = df_gains.where(df_gains['Avg Years Held'] > 0)['Avg Years Held'].mean()\n",
    "    \n",
    "    net_worth = df_gains.loc['Totals'].Gained + df_etf_holdings['Value']\n",
    "\n",
    "    df_results = pd.DataFrame([\n",
    "        df_gains.loc['Totals'].ROI,\n",
    "        format_currency(df_gains.loc['Totals'].Spent),\n",
    "        format_currency(df_gains.loc['Totals'].Gained),\n",
    "        format_currency(df_etf_holdings['Value']),\n",
    "        format_currency(net_worth),\n",
    "        format_currency(df_etf_holdings['Value']),\n",
    "        format_currency(df_etf_holdings['Value'] / net_worth),\n",
    "        str(str(len(filtered_index))) + '/' + str(etfs_available),\n",
    "        months_of_purchase,\n",
    "        df_gains.loc['Totals'].Spent / (months_of_purchase * purchase_interval),\n",
    "        avg_years_held\n",
    "    ],\n",
    "        index=[\n",
    "            'ROI',\n",
    "            'Total Spent',\n",
    "            'Total Gained',\n",
    "            'Total Owned Value',\n",
    "            'Net Worth',\n",
    "            'Holdings',\n",
    "            '% Holdings',\n",
    "            'ETFs Used',\n",
    "            'Months of Purchase',\n",
    "            'Avg Monthly Expense',\n",
    "            'Avg Years Held'\n",
    "        ])\n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2005-01-01'\n",
    "# end_date = '2020-10-01'\n",
    "years_to_sell = 8\n",
    "monthly_budget = 5000 # budget allowed per month\n",
    "purchase_interval = 1 # every {num} of months\n",
    "etf_samples = 5 # number of etfs to be purchased per purchasing session\n",
    "roi_threshold = 0.07 # the minimum ROI to sell the investment\n",
    "\n",
    "run_max_times = 5 # max number of times simulation can run\n",
    "\n",
    "sample_technique = 'top' # where the etf samples are chosen from # can be 'bottom', 'top', or 'none'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run with Configurable Dials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guenther/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run #: 0\n",
      "run time:  -2 seconds\n",
      "run #: 1\n",
      "run time:  -5 seconds\n",
      "run #: 2\n",
      "run time:  -10 seconds\n",
      "run #: 3\n",
      "run time:  -16 seconds\n",
      "run #: 4\n",
      "run time:  -24 seconds\n"
     ]
    }
   ],
   "source": [
    "configuration_dict = {}\n",
    "total_spent = 0\n",
    "total_months = 0\n",
    "months_of_purchase = 0\n",
    "portfolio = {}\n",
    "\n",
    "session_time = np.datetime64('now')\n",
    "\n",
    "def generate_configuration_key():\n",
    "    # @TODO generate start_date, and add to key\n",
    "    config_start_date = np.datetime64(str(random.randint(2000, 2014)) + '-01-01')\n",
    "    \n",
    "    # years_to_sell\n",
    "#     config_years_to_sell = random.randint(5, 10)\n",
    "    global years_to_sell\n",
    "    config_years_to_sell = years_to_sell\n",
    "\n",
    "    \n",
    "    # monthly_budget\n",
    "#     config_monthly_budget = random.randint(1000, 5000)\n",
    "    global monthly_budget\n",
    "    config_monthly_budget = monthly_budget\n",
    "    \n",
    "    # purchase_interval\n",
    "#     config_purchase_interval = random.randint(1, 24)\n",
    "    global purchase_interval\n",
    "    config_purchase_interval = purchase_interval\n",
    "    \n",
    "    #etf_samples\n",
    "#     config_etf_samples = random.randint(1, 20)\n",
    "    global etf_samples\n",
    "    config_etf_samples = etf_samples\n",
    "    \n",
    "    # roi_threshold\n",
    "#     config_roi_threshold = 1 + (random.randint(1, 100) / 100)\n",
    "    global roi_threshold\n",
    "    config_roi_threshold = roi_threshold\n",
    "    \n",
    "    # sample_technique\n",
    "#     config_sample_technique = random.choice(['top', 'bottom', 'none'])\n",
    "    global sample_technique\n",
    "    config_sample_technique = sample_technique\n",
    "    \n",
    "    return {\n",
    "        'start_date': config_start_date,\n",
    "        'years_to_sell': config_years_to_sell,\n",
    "        'monthly_budget': config_monthly_budget,\n",
    "        'purchase_interval': config_purchase_interval,\n",
    "        'etf_samples': config_etf_samples,\n",
    "        'config_roi_threshold': config_roi_threshold,\n",
    "        'config_sample_technique': config_sample_technique,\n",
    "        'key': (\n",
    "            str(config_start_date) +\n",
    "            ':' +\n",
    "            str(config_years_to_sell) + \n",
    "            ':' + \n",
    "            str(config_monthly_budget) + \n",
    "            ':' + \n",
    "            str(config_purchase_interval) + \n",
    "            ':' + \n",
    "            str(config_etf_samples) +\n",
    "            ':' +\n",
    "            str(config_roi_threshold) +\n",
    "            ':' +\n",
    "            config_sample_technique\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    \n",
    "def has_scenario_ran(config_key):\n",
    "    global configuration_dict\n",
    "    if config_key['key'] in configuration_dict:\n",
    "        return True\n",
    "    \n",
    "    configuration_dict[config_key['key']] = True\n",
    "    return False\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "columns = [\n",
    "    'Start Date', \n",
    "    'Min Years Held', \n",
    "    'Interval', \n",
    "    'ETF Samples', \n",
    "    'ROI', \n",
    "    'Monthly Expense',\n",
    "    'Monthly Budget',\n",
    "    'Avg Years Held',\n",
    "    'Holdings',\n",
    "    '% Holdings',\n",
    "    'Net Worth'\n",
    "]\n",
    "\n",
    "df_results = pd.DataFrame([], columns=columns)\n",
    "\n",
    "configuration_key = generate_configuration_key()\n",
    "while not has_scenario_ran(configuration_key):\n",
    "    global start_date\n",
    "    global years_to_sell\n",
    "    global monthly_budget\n",
    "    global purchase_interval\n",
    "    global etf_samples\n",
    "    global roi_threshold\n",
    "    global sample_technique\n",
    "    \n",
    "    # update config values\n",
    "    start_date = configuration_key['start_date']\n",
    "    years_to_sell = configuration_key['years_to_sell']\n",
    "    monthly_budget = configuration_key['monthly_budget']\n",
    "    purchase_interval = configuration_key['purchase_interval']\n",
    "    etf_samples = configuration_key['etf_samples']\n",
    "    roi_threshold = configuration_key['config_roi_threshold']\n",
    "    sample_technique = configuration_key['config_sample_technique']\n",
    "    \n",
    "    df_new_results = get_results()\n",
    "    df_next_results = pd.DataFrame([[\n",
    "        start_date,\n",
    "        years_to_sell,\n",
    "        purchase_interval / 12,\n",
    "        etf_samples,\n",
    "        df_new_results.loc['ROI'][0], \n",
    "#         df_new_results.loc['Avg Monthly Expense'][0],\n",
    "        total_spent / total_months,\n",
    "        monthly_budget,\n",
    "        df_new_results.loc['Avg Years Held'][0],\n",
    "        df_new_results.loc['Holdings'][0],\n",
    "        df_new_results.loc['% Holdings'][0],\n",
    "        df_new_results.loc['Net Worth'][0]\n",
    "    ]],\n",
    "        columns=columns)\n",
    "\n",
    "    df_results = df_results.append(df_next_results)\n",
    "    \n",
    "    print('run #: ' + str(i))\n",
    "    print('run time: ', (np.datetime64('now') - session_time))\n",
    "    \n",
    "    \n",
    "#     global configuration_key\n",
    "    configuration_key = generate_configuration_key()\n",
    "    \n",
    "    i += 1\n",
    "    if i > run_max_times:\n",
    "        break\n",
    "        \n",
    "df_results = df_results.reset_index()\n",
    "df_results = df_results.drop('index', axis=1).dropna()\n",
    "df_results['Technique'] = sample_technique\n",
    "\n",
    "# save results\n",
    "# results_path = './results.csv'\n",
    "# if path.exists(results_path):\n",
    "#     df_saved = pd.read_csv(results_path)\n",
    "#     df_results = pd.concat([df_saved, df_results])\n",
    "#     df_results = df_results.reset_index().drop(['Unnamed: 0', 'index'], axis=1)\n",
    "    \n",
    "df_results.to_csv(results_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Years Held        8.000000\n",
      "Interval              0.083333\n",
      "ETF Samples           5.000000\n",
      "ROI                   1.320002\n",
      "Monthly Expense    4839.450989\n",
      "Monthly Budget     5000.000000\n",
      "Avg Years Held        7.163679\n",
      "dtype: float64\n",
      "  Start Date Min Years Held  Interval ETF Samples       ROI  Monthly Expense  \\\n",
      "2 2009-01-01              8  0.083333           5  1.879260      4839.915337   \n",
      "3 2005-01-01              8  0.083333           5  1.123922      4836.434481   \n",
      "4 2002-01-01              8  0.083333           5  0.956823      4842.003150   \n",
      "\n",
      "  Monthly Budget  Avg Years Held      Holdings % Holdings     Net Worth  \\\n",
      "2           5000        7.157303  2,477,733.61       0.85  2,902,014.25   \n",
      "3           5000        7.178236  3,379,015.07       0.87  3,885,696.05   \n",
      "4           5000        7.155496  4,280,296.52       0.88  4,883,174.32   \n",
      "\n",
      "  Technique  \n",
      "2       top  \n",
      "3       top  \n",
      "4       top  \n"
     ]
    }
   ],
   "source": [
    "df_results['Start Date'] = df_results['Start Date'].astype('datetime64[D]')\n",
    "print(df_results.mean())\n",
    "\n",
    "print(df_results)\n",
    "\n",
    "# df_results['Net Worth'] = df_results['Net Worth'].str.replace(r',', '').astype(float)\n",
    "# print(df_results.sort_values('Net Worth', ascending=False))\n",
    "# print(df_results.sort_values('Net Worth', ascending=False).dropna().head(30))\n",
    "\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#     df_results['Start Date'] = df_results['Start Date'].astype('datetime64[D]')\n",
    "# #     df_results['Positive ROI'] = df_results['ROI'] > 0\n",
    "# #     df_results = df_results.where(df_results['Technique'] == 'top')\n",
    "#     df_segment = df_results.drop(['Monthly Budget', 'Min Years Held'], axis=1).sort_values('Interval', ascending=True)\n",
    "#     df_segment_length = math.floor(len(df_segment.index.tolist()) / 2)\n",
    "#     df_segment_1 = df_segment.iloc[:df_segment_length, :]\n",
    "#     df_segment_2 = df_segment.iloc[df_segment_length:, :]\n",
    "\n",
    "# #     df_segment_1 = df_results.where(df_results['Technique'] == 'top')\n",
    "# #     df_segment_2 = df_results.where(df_results['Technique'] == 'bottom')\n",
    "    \n",
    "#     print(df_segment_1.mean())\n",
    "#     print(df_segment_2.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drill Into Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Best Min Years  Best Avg Years Held  Best Interval  Best ETF Samples\n",
      "0              10                  9.0       0.083333                 5\n"
     ]
    }
   ],
   "source": [
    "# format Start Date to be uniform\n",
    "df_results['Start Date'] = df_results['Start Date'].astype('datetime64[D]')\n",
    "\n",
    "# determine which sample_technique produced the highest chance of positive results\n",
    "df_results['Positive ROI'] = df_results['ROI'] > 0\n",
    "df_bottom_segment = df_results.where(df_results['Technique'] == 'bottom').dropna(how='all')\n",
    "df_top_segment = df_results.where(df_results['Technique'] == 'top').dropna(how='all')\n",
    "df_none_segment = df_results.where(df_results['Technique'] == 'none').dropna(how='all')\n",
    "\n",
    "sample_technique_segment_positive_rois = [\n",
    "    df_bottom_segment.mean()['Positive ROI'],\n",
    "    df_top_segment.mean()['Positive ROI'],\n",
    "    df_none_segment.mean()['Positive ROI']\n",
    "]\n",
    "\n",
    "highest_positive_rois = max(sample_technique_segment_positive_rois)\n",
    "\n",
    "least_risk_candidate = None\n",
    "if highest_positive_rois == sample_technique_segment_positive_rois[0]:\n",
    "    least_risk_candidate = df_bottom_segment\n",
    "elif highest_positive_rois == sample_technique_segment_positive_rois[1]:\n",
    "    least_risk_candidate = df_top_segment\n",
    "else:\n",
    "    least_risk_candidate = df_none_segment\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_best_from_column(df, col):\n",
    "    if len(df.index.tolist()) == 1:\n",
    "        return df[col].values[0]\n",
    "    \n",
    "    # determine the characteristics that make up the highest ROI\n",
    "    df_segmentation = df.sort_values(col, ascending=True)\n",
    "    df_segmentation_length = math.floor(len(df_segmentation.index.tolist()) / 2)\n",
    "    df_segment_1 = df_segmentation.iloc[df_segmentation_length:, :]\n",
    "    df_segment_2 = df_segmentation.iloc[:df_segmentation_length, :]\n",
    "\n",
    "#     print(df_segment_1.mean())\n",
    "#     print(df_segment_2.mean())\n",
    "\n",
    "    # use whichever one produced the higher ROI\n",
    "    if df_segment_1.mean()['ROI'] > df_segment_2.mean()['ROI']:\n",
    "        return get_best_from_column(df_segment_1, col)\n",
    "    else:\n",
    "        return get_best_from_column(df_segment_2, col)\n",
    "        \n",
    "\n",
    "# print(least_risk_candidate.head())\n",
    "        \n",
    "best_min_years_held = get_best_from_column(least_risk_candidate, 'Min Years Held')\n",
    "best_start_date = get_best_from_column(least_risk_candidate, 'Start Date')\n",
    "best_interval = get_best_from_column(least_risk_candidate, 'Interval')\n",
    "best_etf_samples = get_best_from_column(least_risk_candidate, 'ETF Samples')\n",
    "best_avg_years_held = get_best_from_column(least_risk_candidate, 'Avg Years Held')\n",
    "\n",
    "\n",
    "df_bests = pd.DataFrame([[\n",
    "    best_min_years_held,\n",
    "    best_avg_years_held,\n",
    "    best_interval,\n",
    "    best_etf_samples,\n",
    "]],\n",
    "    columns=[\n",
    "        'Best Min Years',\n",
    "        'Best Avg Years Held',\n",
    "        'Best Interval',\n",
    "        'Best ETF Samples'\n",
    "    ])\n",
    "\n",
    "print(df_bests)\n",
    "\n",
    "\n",
    "# df_segment_1 = df_segmentation[df_segmentation_length:, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
